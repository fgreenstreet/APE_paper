{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt5\n",
    "\n",
    "import sys\n",
    "sys.path.append('..\\..')\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.behaviour_utils import RBias, CalculateRBiasWindow\n",
    "import matplotlib\n",
    "from utils.post_processing_utils import *\n",
    "from utils.plotting import calculate_error_bars, multi_conditions_plot\n",
    "from set_global_params import value_change_mice, figure_directory, reproduce_figures_path, spreadsheet_path\n",
    "from utils.stats import cohen_d_paired\n",
    "from save_to_excel import save_figure_data_to_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making sure files are where they need to be - don't need to run if you have repro data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case the repro data file doesn't exist, copy it over from the raw path \n",
    "# (don't run if you don't have the full data set and only have repro data - will throw error)\n",
    "repro_dir = os.path.join(reproduce_figures_path, 'ED_fig6', 'value_change_behaviour')\n",
    "mice = value_change_mice['Nacc'] + value_change_mice['tail']\n",
    "for mouse_num, mouse_id in enumerate(mice):\n",
    "    all_experiments = get_all_experimental_records()\n",
    "    sessions = all_experiments[(all_experiments['mouse_id'] == mouse_id) & (all_experiments['experiment_notes'] == 'value switch')]['date'].values\n",
    "    for date in sessions:\n",
    "        experiment_to_process = all_experiments[(all_experiments['date'] == date) & (all_experiments['mouse_id'] == mouse_id)]\n",
    "        copy_behaviour_to_folder_mouse_name(experiment_to_process, source_dir=processed_data_path, target_dir=repro_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, window=50):\n",
    "    rolling_average = np.empty(len(x))\n",
    "    rolling_average[:] = np.nan\n",
    "    for i in range(window, len(x)):\n",
    "        win = range((i - window), i)\n",
    "        rolling_average[i] = np.mean(x[win])\n",
    "    return rolling_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "repro_dir = os.path.join(reproduce_figures_path, 'ED_fig6', 'value_change_behaviour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pc = []\n",
    "post_pc = []\n",
    "mice = value_change_mice['Nacc']\n",
    "mouse_ids = []\n",
    "session_ids = []\n",
    "moving_avs = []\n",
    "reward_blocks = []\n",
    "performance_to_delvalued_tone = []\n",
    "for mouse_num, mouse_id in enumerate(mice):\n",
    "    all_experiments = get_all_experimental_records()\n",
    "    sessions = all_experiments[(all_experiments['mouse_id'] == mouse_id) & (all_experiments['experiment_notes'] == 'value switch')]['date'].values\n",
    "    for date in sessions:\n",
    "        experiment_to_process = all_experiments[(all_experiments['date'] == date) & (all_experiments['mouse_id'] == mouse_id)]\n",
    "        trial_data = open_experiment_just_behaviour(experiment_to_process, root_dir=repro_dir)\n",
    "        trial_data.loc[trial_data['Trial outcome'] == 3, 'Trial outcome'] = 0\n",
    "        red_trial_data = trial_data[trial_data['State name'] == 'TrialStart']\n",
    "        post_trials = red_trial_data[red_trial_data['Trial num'] >= 100]\n",
    "        pre_trials = red_trial_data[red_trial_data['Trial num'] < 100]\n",
    "        post_reward_side = post_trials['Reward block'].unique()[0]\n",
    "        if post_reward_side == 1:\n",
    "            side = -1\n",
    "            devalued_trial_type = 7\n",
    "        elif post_reward_side == 5:\n",
    "            side = 1\n",
    "            devalued_trial_type = 1\n",
    "        devalued_trials = post_trials[post_trials['Trial type'] == devalued_trial_type]\n",
    "        performance = np.mean(devalued_trials['Trial outcome'].values) * 100\n",
    "        pre_bias = RBias(pre_trials['First response'], pre_trials['First choice correct'])* side\n",
    "        post_bias = RBias(post_trials['First response'], post_trials['First choice correct']) *side\n",
    "        post_pc.append(post_bias)\n",
    "        pre_pc.append(pre_bias)\n",
    "        session_ids.append(date)\n",
    "        mouse_ids.append(mouse_id)\n",
    "        reward_blocks.append(post_reward_side)\n",
    "        performance_to_delvalued_tone.append(performance)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = value_change_mice['tail']\n",
    "for mouse_num, mouse_id in enumerate(mice):\n",
    "    all_experiments = get_all_experimental_records()\n",
    "    sessions = all_experiments[(all_experiments['mouse_id'] == mouse_id) & (all_experiments['experiment_notes'] == 'value switch')]['date'].values\n",
    "    for date in sessions:\n",
    "        experiment_to_process = all_experiments[(all_experiments['date'] == date) & (all_experiments['mouse_id'] == mouse_id)]\n",
    "        trial_data = open_experiment_just_behaviour(experiment_to_process, root_dir=repro_dir)\n",
    "        trial_data.loc[trial_data['Trial outcome'] == 3, 'Trial outcome'] = 0\n",
    "        red_trial_data = trial_data[trial_data['State name'] == 'TrialStart']\n",
    "        post_trials = red_trial_data[red_trial_data['Trial num'] >= 100]\n",
    "        pre_trials = red_trial_data[red_trial_data['Trial num'] < 100]\n",
    "        post_reward_side = post_trials['Reward block'].unique()[0]\n",
    "        if post_reward_side == 1:\n",
    "            side = -1\n",
    "            devalued_trial_type = 7\n",
    "        elif post_reward_side == 5:\n",
    "            side = 1\n",
    "            devalued_trial_type = 1\n",
    "        devalued_trials = post_trials[post_trials['Trial type'] == devalued_trial_type]\n",
    "        performance = np.mean(devalued_trials['Trial outcome'].values) * 100\n",
    "        pre_bias = RBias(pre_trials['First response'], pre_trials['First choice correct'])* side\n",
    "        post_bias = RBias(post_trials['First response'], post_trials['First choice correct']) *side\n",
    "        post_pc.append(post_bias)\n",
    "        pre_pc.append(pre_bias)\n",
    "        session_ids.append(date)\n",
    "        mouse_ids.append(mouse_id)\n",
    "        reward_blocks.append(post_reward_side)\n",
    "        performance_to_delvalued_tone.append(performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francescag\\AppData\\Local\\Continuum\\miniconda3\\envs\\py38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "behavioural_change_performance = {}\n",
    "behavioural_change_performance['mouse'] = mouse_ids\n",
    "behavioural_change_performance['session'] = session_ids\n",
    "behavioural_change_performance['performance to devalued tone'] = performance_to_delvalued_tone \n",
    "behavioural_change_performance_df = pd.DataFrame(behavioural_change_performance)\n",
    "\n",
    "per_mouse_performance = behavioural_change_performance_df.groupby(['mouse'])[['performance to devalued tone']].apply(np.mean)\n",
    "per_mouse_performance = per_mouse_performance.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.9938010150495"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(per_mouse_performance['performance to devalued tone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.239987618045049"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(per_mouse_performance['performance to devalued tone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioural_change = {}\n",
    "behavioural_change['mouse'] = mouse_ids\n",
    "behavioural_change['session'] = session_ids\n",
    "behavioural_change['pre bias'] = pre_pc \n",
    "behavioural_change['post bias'] = post_pc\n",
    "behavioural_change_df = pd.DataFrame(behavioural_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francescag\\AppData\\Local\\Continuum\\miniconda3\\envs\\py38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_for_plot = behavioural_change_df.groupby(['mouse'])[['pre bias', 'post bias']].apply(np.mean)*100\n",
    "df_for_plot = df_for_plot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot1 = df_for_plot.set_index('mouse').transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_csv = os.path.join(spreadsheet_path, 'ED_fig6', 'ED_fig6U_bias_to_big_value_change.csv')\n",
    "if not os.path.exists(comparison_csv):\n",
    "    (df_for_plot1.T).to_csv(comparison_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size': 7}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Arial'\n",
    "matplotlib.rcParams['font.family']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[2,2])\n",
    "multi_conditions_plot(ax, df_for_plot1, mean_line_color='#7FB5B5', mean_linewidth=6, show_err_bar=False)\n",
    "plt.xticks([0, 1], ['equal\\nrewards', 'unequal\\nrewards'])\n",
    "plt.ylabel('Bias towards BIG side (%)')\n",
    "\n",
    "y = df_for_plot1.to_numpy().max() + .2\n",
    "h = 1\n",
    "plt.plot([0, 0, 1, 1], [y, y+h, y+h, y],c='k',lw=1)\n",
    "ax.text(.5, y+h, '**', ha='center', fontsize=8)\n",
    "plt.tight_layout()\n",
    "figure_dir = figure_directory\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017325467666258832"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "pre_data = df_for_plot1.T['pre bias'].values\n",
    "post_data = df_for_plot1.T['post bias'].values\n",
    "stat, pval = stats.ttest_rel(pre_data, post_data)\n",
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohen d:  1.3898675116302859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3898675116302859"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_d_paired(post_data, pre_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.688087278321691"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df_for_plot1.T['post bias'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.31191272167831"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(100 - (df_for_plot1.T['post bias'].values + 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.9447067379951477, pvalue=0.6064687371253967)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differences = pre_data - post_data\n",
    "stats.shapiro(differences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.697722384256606"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_plot1.to_numpy().max() + .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_per_mouse_mean(mouse_moving_avs):\n",
    "    num_sessions = len(mouse_moving_avs)\n",
    "    num_trials = [len(m) for m in mouse_moving_avs]\n",
    "    min_num_trials = min(num_trials)\n",
    "    all_sessions = np.empty((num_sessions, min_num_trials))\n",
    "    all_sessions[:] = np.nan\n",
    "    for i, session_data in enumerate(mouse_moving_avs):\n",
    "        all_sessions[i, :min_num_trials] = session_data[:min_num_trials]\n",
    "    moving_av = np.nanmean(all_sessions, axis=0)\n",
    "    return moving_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_mulitple_mice_moving_avs(mice, moving_avs):\n",
    "    num_mice = len(mice)\n",
    "    num_trials = [len(m) for m in moving_avs]\n",
    "    min_num_trials = min([len(m) for m in moving_avs])\n",
    "    all_mice = np.empty((num_mice, min_num_trials))\n",
    "    all_mice[:] = np.nan\n",
    "    for i, mouse_data in enumerate(moving_avs):\n",
    "        all_mice[i, :min_num_trials] = mouse_data[:min_num_trials]\n",
    "    return all_mice, min_num_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SNL_photo70', 'SNL_photo72', 'SNL_photo37', 'SNL_photo43', 'SNL_photo44', 'SNL_photo30', 'SNL_photo31', 'SNL_photo32', 'SNL_photo34', 'SNL_photo35']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\421496107.py:9: RuntimeWarning: Mean of empty slice\n",
      "  moving_av = np.nanmean(all_sessions, axis=0)\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\421496107.py:9: RuntimeWarning: Mean of empty slice\n",
      "  moving_av = np.nanmean(all_sessions, axis=0)\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\421496107.py:9: RuntimeWarning: Mean of empty slice\n",
      "  moving_av = np.nanmean(all_sessions, axis=0)\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\421496107.py:9: RuntimeWarning: Mean of empty slice\n",
      "  moving_av = np.nanmean(all_sessions, axis=0)\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\421496107.py:9: RuntimeWarning: Mean of empty slice\n",
      "  moving_av = np.nanmean(all_sessions, axis=0)\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\421496107.py:9: RuntimeWarning: Mean of empty slice\n",
      "  moving_av = np.nanmean(all_sessions, axis=0)\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\421496107.py:9: RuntimeWarning: Mean of empty slice\n",
      "  moving_av = np.nanmean(all_sessions, axis=0)\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\421496107.py:9: RuntimeWarning: Mean of empty slice\n",
      "  moving_av = np.nanmean(all_sessions, axis=0)\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\421496107.py:9: RuntimeWarning: Mean of empty slice\n",
      "  moving_av = np.nanmean(all_sessions, axis=0)\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\421496107.py:9: RuntimeWarning: Mean of empty slice\n",
      "  moving_av = np.nanmean(all_sessions, axis=0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "moving_avs = []\n",
    "response_times = []\n",
    "missed_trials = []\n",
    "performance = []\n",
    "\n",
    "mice = value_change_mice['tail'] + value_change_mice['Nacc']\n",
    "print(mice)\n",
    "for mouse_num, mouse_id in enumerate(mice):\n",
    "    all_experiments = get_all_experimental_records()\n",
    "    sessions = all_experiments[(all_experiments['mouse_id'] == mouse_id) & (all_experiments['experiment_notes'] == 'value switch')]['date'].values\n",
    "    mouse_moving_avs = []\n",
    "    mouse_response_times = []\n",
    "    mouse_missed_trials = []\n",
    "    mouse_performance = []\n",
    "    for date in sessions:\n",
    "        experiment_to_process = all_experiments[(all_experiments['date'] == date) & (all_experiments['mouse_id'] == mouse_id)]\n",
    "        trial_data = open_experiment_just_behaviour(experiment_to_process, root_dir=repro_dir)\n",
    "        red_trial_data = trial_data[trial_data['State name'] == 'TrialStart']\n",
    "        red_trial_data_for_missed_trials = trial_data[trial_data['State name'] == 'TrialStart']\n",
    "        red_trial_data_for_missed_trials.loc[trial_data['Trial outcome'] == 1, 'Trial outcome'] = 0\n",
    "        red_trial_data_for_missed_trials.loc[trial_data['Trial outcome'] == 3, 'Trial outcome'] = 1\n",
    "        red_trial_data.loc[trial_data['Trial outcome'] == 3, 'Trial outcome'] = 0\n",
    "        response_trial_data = trial_data[trial_data['State name'] == 'WaitForResponse']\n",
    "        post_trials = red_trial_data[red_trial_data['Trial num'] >= 100]\n",
    "        pre_trials = red_trial_data[red_trial_data['Trial num'] < 100]\n",
    "        post_reward_side = post_trials['Reward block'].unique()[0]\n",
    "        if post_reward_side == 1: #left\n",
    "            side = -1\n",
    "        elif post_reward_side == 5: #right\n",
    "            side = 1\n",
    "        mouse_moving_avs.append(CalculateRBiasWindow(red_trial_data['First response'].reset_index(drop=True), red_trial_data['First choice correct'].reset_index(drop=True), 20) *side*100)\n",
    "        mouse_response_times.append(moving_average(response_trial_data['Time end'].values - response_trial_data['Time start'].values, window=20))\n",
    "        mouse_missed_trials.append(moving_average(red_trial_data_for_missed_trials['Trial outcome'].values, window=20) * 100, )\n",
    "        mouse_performance.append(moving_average(red_trial_data['Trial outcome'].values, window=20) * 100)\n",
    "    response_times.append(calc_per_mouse_mean(mouse_response_times))\n",
    "    moving_avs.append(calc_per_mouse_mean(mouse_moving_avs))\n",
    "    performance.append(calc_per_mouse_mean(mouse_performance))\n",
    "    missed_trials.append(calc_per_mouse_mean(mouse_missed_trials))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9366197183098591"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_trials['Trial outcome'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_trials['Trial outcome'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rolling_mean(var, mice, moving_avs, y_axis_label='% bias to big reward side'):\n",
    "    \n",
    "    all_mice, min_num_trials = align_mulitple_mice_moving_avs(mice, moving_avs)\n",
    "    error_bar_lower, error_bar_upper = calculate_error_bars(np.nanmean(all_mice, axis=0),\n",
    "                                                                     all_mice,\n",
    "                                                                    error_bar_method='sem')\n",
    "    font = {'size': 8}\n",
    "    matplotlib.rc('font', **font)\n",
    "    matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "    matplotlib.rcParams['font.sans-serif'] = 'Arial'\n",
    "    matplotlib.rcParams['font.family']\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1, figsize=[2.5, 2])\n",
    "    [axs.plot(m[:min_num_trials], alpha=0.5, c='gray', lw=0.5, label=f'mouse {i}') for i, m in enumerate(moving_avs)]\n",
    "    axs.plot(np.nanmean(all_mice,axis=0), c='#5e8c89', lw=1, label='mean')\n",
    "    axs.fill_between(np.arange(0, min_num_trials), error_bar_lower, error_bar_upper, alpha=0.5,\n",
    "                                facecolor='#7FB5B5', linewidth=0)\n",
    "\n",
    "    axs.axvline(100, color='k', label='block switch')\n",
    "    axs.set_xlabel('trial number')\n",
    "    axs.set_ylabel(y_axis_label)\n",
    "    axs.spines['right'].set_visible(False)\n",
    "    axs.spines['top'].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figure_directory, '{} developing over trials.pdf'.format(var)))\n",
    "\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling mean bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\3170320309.py:4: RuntimeWarning: Mean of empty slice\n",
      "  error_bar_lower, error_bar_upper = calculate_error_bars(np.nanmean(all_mice, axis=0),\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\3170320309.py:16: RuntimeWarning: Mean of empty slice\n",
      "  axs.plot(np.nanmean(all_mice,axis=0), c='#5e8c89', lw=1, label='mean')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to S:\\projects\\APE_data_francesca_for_paper\\spreadsheets_for_nature\\ED_fig6\\ED_fig6Y_bias_value_change.xlsx\n"
     ]
    }
   ],
   "source": [
    "bias_fig = plot_rolling_mean('bias', mice, moving_avs, y_axis_label='% bias to big reward side')\n",
    "bias_xl = os.path.join(spreadsheet_path, 'ED_fig6', 'ED_fig6Y_bias_value_change.xlsx')\n",
    "if not os.path.exists(bias_xl):\n",
    "    save_figure_data_to_excel(bias_fig, bias_xl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling mean response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\3170320309.py:4: RuntimeWarning: Mean of empty slice\n",
      "  error_bar_lower, error_bar_upper = calculate_error_bars(np.nanmean(all_mice, axis=0),\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\3170320309.py:16: RuntimeWarning: Mean of empty slice\n",
      "  axs.plot(np.nanmean(all_mice,axis=0), c='#5e8c89', lw=1, label='mean')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to S:\\projects\\APE_data_francesca_for_paper\\spreadsheets_for_nature\\ED_fig6\\ED_fig6X_response_time_state_change.xlsx\n"
     ]
    }
   ],
   "source": [
    "response_time_fig = plot_rolling_mean('response time', mice, response_times, y_axis_label='response time (s)')\n",
    "response_time_xl = os.path.join(spreadsheet_path, 'ED_fig6', 'ED_fig6X_response_time_state_change.xlsx')\n",
    "if not os.path.exists(response_time_xl):\n",
    "    save_figure_data_to_excel(response_time_fig, response_time_xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\3170320309.py:4: RuntimeWarning: Mean of empty slice\n",
      "  error_bar_lower, error_bar_upper = calculate_error_bars(np.nanmean(all_mice, axis=0),\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\3170320309.py:16: RuntimeWarning: Mean of empty slice\n",
      "  axs.plot(np.nanmean(all_mice,axis=0), c='#5e8c89', lw=1, label='mean')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to S:\\projects\\APE_data_francesca_for_paper\\spreadsheets_for_nature\\ED_fig6\\ED_fig6W_performance_state_change.xlsx\n"
     ]
    }
   ],
   "source": [
    "performance_fig = plot_rolling_mean('performance', mice, performance, y_axis_label='% correct')\n",
    "performance_xl = os.path.join(spreadsheet_path, 'ED_fig6', 'ED_fig6W_performance_state_change.xlsx')\n",
    "if not os.path.exists(performance_xl):\n",
    "    save_figure_data_to_excel(performance_fig, performance_xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\3170320309.py:4: RuntimeWarning: Mean of empty slice\n",
      "  error_bar_lower, error_bar_upper = calculate_error_bars(np.nanmean(all_mice, axis=0),\n",
      "C:\\Users\\francescag\\AppData\\Local\\Temp\\ipykernel_1308\\3170320309.py:16: RuntimeWarning: Mean of empty slice\n",
      "  axs.plot(np.nanmean(all_mice,axis=0), c='#5e8c89', lw=1, label='mean')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to S:\\projects\\APE_data_francesca_for_paper\\spreadsheets_for_nature\\ED_fig6\\ED_fig6V_missed_state_change.xlsx\n"
     ]
    }
   ],
   "source": [
    "missed_fig = plot_rolling_mean('missed trials', mice, missed_trials, y_axis_label='% missed trials')\n",
    "missed_xl = os.path.join(spreadsheet_path, 'ED_fig6', 'ED_fig6V_missed_state_change.xlsx')\n",
    "if not os.path.exists(missed_xl):\n",
    "    save_figure_data_to_excel(missed_fig, missed_xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
